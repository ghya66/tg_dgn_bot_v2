#!/usr/bin/env python3
"""
æ¶æ„è¿ç§»å¯åŠ¨è„šæœ¬
è‡ªåŠ¨åˆ›å»ºæ–°çš„DDDç›®å½•ç»“æ„å¹¶å‡†å¤‡è¿ç§»
"""
import os
import shutil
from pathlib import Path
from datetime import datetime
import json

class ArchitectureMigration:
    """æ¶æ„è¿ç§»ç®¡ç†å™¨"""
    
    def __init__(self):
        self.base_path = Path(".")
        self.backup_path = Path("backups") / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
    def create_backup(self):
        """åˆ›å»ºå¤‡ä»½"""
        print("ğŸ“¦ åˆ›å»ºå¤‡ä»½...")
        
        # éœ€è¦å¤‡ä»½çš„ç›®å½•
        dirs_to_backup = ["src", "tests", "scripts"]
        
        for dir_name in dirs_to_backup:
            if (self.base_path / dir_name).exists():
                backup_dir = self.backup_path / dir_name
                shutil.copytree(
                    self.base_path / dir_name,
                    backup_dir,
                    ignore=shutil.ignore_patterns('__pycache__', '*.pyc')
                )
                print(f"  âœ… å¤‡ä»½ {dir_name} -> {backup_dir}")
        
        # å¤‡ä»½é‡è¦æ–‡ä»¶
        files_to_backup = [
            "requirements.txt",
            ".env",
            "docker-compose.yml",
            "README.md"
        ]
        
        for file_name in files_to_backup:
            if (self.base_path / file_name).exists():
                backup_file = self.backup_path / file_name
                backup_file.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(self.base_path / file_name, backup_file)
                print(f"  âœ… å¤‡ä»½ {file_name}")
    
    def create_ddd_structure(self):
        """åˆ›å»ºDDDç›®å½•ç»“æ„"""
        print("\nğŸ—ï¸ åˆ›å»ºDDDæ¶æ„...")
        
        directories = [
            # Domainå±‚
            "domain/entities",
            "domain/value_objects", 
            "domain/services",
            "domain/repositories",
            "domain/events",
            "domain/specifications",
            
            # Applicationå±‚
            "application/commands",
            "application/queries",
            "application/dto",
            "application/services",
            "application/validators",
            
            # Infrastructureå±‚
            "infrastructure/database/postgresql",
            "infrastructure/database/redis",
            "infrastructure/database/migrations",
            "infrastructure/messaging/rabbitmq",
            "infrastructure/monitoring",
            "infrastructure/external/telegram",
            "infrastructure/external/tron",
            "infrastructure/external/payment",
            
            # Presentationå±‚
            "presentation/handlers/premium",
            "presentation/handlers/wallet",
            "presentation/handlers/energy",
            "presentation/handlers/admin",
            "presentation/middlewares",
            "presentation/routers",
            "presentation/validators",
            
            # Sharedå±‚
            "shared/exceptions",
            "shared/utils",
            "shared/constants",
            "shared/decorators",
            
            # Tests
            "tests/unit/domain",
            "tests/unit/application",
            "tests/integration",
            "tests/e2e",
            "tests/fixtures",
            "tests/mocks",
            
            # Documentation
            "docs/architecture",
            "docs/api",
            "docs/deployment",
            "docs/development",
            "docs/operations",
            
            # Configuration
            "config/environments",
            "config/k8s",
            "config/docker",
        ]
        
        for dir_path in directories:
            full_path = self.base_path / dir_path
            full_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»º__init__.py
            init_file = full_path / "__init__.py"
            if not init_file.exists():
                init_file.write_text('"""\n{}\n"""\n'.format(
                    dir_path.replace('/', '.') + ' module'
                ))
            
            print(f"  âœ… åˆ›å»º {dir_path}")
    
    def create_base_files(self):
        """åˆ›å»ºåŸºç¡€æ–‡ä»¶"""
        print("\nğŸ“„ åˆ›å»ºåŸºç¡€æ–‡ä»¶...")
        
        # Domainå®ä½“åŸºç±»
        base_entity = '''"""
é¢†åŸŸå®ä½“åŸºç±»
"""
from dataclasses import dataclass
from datetime import datetime
from typing import Optional
import uuid

@dataclass
class Entity:
    """å®ä½“åŸºç±»"""
    id: str
    created_at: datetime
    updated_at: datetime
    
    def __init__(self, id: Optional[str] = None):
        self.id = id or str(uuid.uuid4())
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
    
    def __eq__(self, other):
        if not isinstance(other, Entity):
            return False
        return self.id == other.id
'''
        (self.base_path / "domain/entities/base.py").write_text(base_entity)
        print("  âœ… åˆ›å»º domain/entities/base.py")
        
        # Repositoryæ¥å£
        repository_interface = '''"""
ä»“åº“æ¥å£å®šä¹‰
"""
from abc import ABC, abstractmethod
from typing import Optional, List, Generic, TypeVar

T = TypeVar('T')

class Repository(ABC, Generic[T]):
    """ä»“åº“åŸºç¡€æ¥å£"""
    
    @abstractmethod
    async def get_by_id(self, id: str) -> Optional[T]:
        """æ ¹æ®IDè·å–"""
        pass
    
    @abstractmethod
    async def get_all(self) -> List[T]:
        """è·å–æ‰€æœ‰"""
        pass
    
    @abstractmethod
    async def save(self, entity: T) -> T:
        """ä¿å­˜å®ä½“"""
        pass
    
    @abstractmethod
    async def delete(self, id: str) -> bool:
        """åˆ é™¤å®ä½“"""
        pass
'''
        (self.base_path / "domain/repositories/base.py").write_text(repository_interface)
        print("  âœ… åˆ›å»º domain/repositories/base.py")
        
        # åº”ç”¨æœåŠ¡åŸºç±»
        app_service = '''"""
åº”ç”¨æœåŠ¡åŸºç±»
"""
from typing import Dict, Any
import logging

logger = logging.getLogger(__name__)

class ApplicationService:
    """åº”ç”¨æœåŠ¡åŸºç±»"""
    
    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡ŒæœåŠ¡"""
        raise NotImplementedError
    
    def validate(self, **kwargs):
        """éªŒè¯è¾“å…¥"""
        pass
'''
        (self.base_path / "application/services/base.py").write_text(app_service)
        print("  âœ… åˆ›å»º application/services/base.py")
        
    def create_docker_files(self):
        """åˆ›å»ºDockerç›¸å…³æ–‡ä»¶"""
        print("\nğŸ³ åˆ›å»ºDockeré…ç½®...")
        
        # Docker Compose
        docker_compose = '''version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: tg_bot_postgres
    environment:
      POSTGRES_DB: tg_bot
      POSTGRES_USER: bot_user
      POSTGRES_PASSWORD: ${DB_PASSWORD:-password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U bot_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: tg_bot_redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  bot:
    build: .
    container_name: tg_bot
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - BOT_TOKEN=${BOT_TOKEN}
      - DATABASE_URL=postgresql+asyncpg://bot_user:${DB_PASSWORD:-password}@postgres:5432/tg_bot
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
'''
        (self.base_path / "docker-compose.prod.yml").write_text(docker_compose)
        print("  âœ… åˆ›å»º docker-compose.prod.yml")
        
        # Dockerfile
        dockerfile = '''FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \\
    gcc \\
    postgresql-client \\
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY . .

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\
  CMD python -c "import requests; requests.get('http://localhost:8080/health')"

# è¿è¡Œ
CMD ["python", "-m", "presentation.main"]
'''
        (self.base_path / "Dockerfile.prod").write_text(dockerfile)
        print("  âœ… åˆ›å»º Dockerfile.prod")
        
    def create_migration_plan(self):
        """åˆ›å»ºè¿ç§»è®¡åˆ’"""
        print("\nğŸ“‹ ç”Ÿæˆè¿ç§»è®¡åˆ’...")
        
        plan = {
            "version": "1.0",
            "created_at": datetime.now().isoformat(),
            "phases": [
                {
                    "phase": 1,
                    "name": "å‡†å¤‡é˜¶æ®µ",
                    "tasks": [
                        "å¤‡ä»½ç°æœ‰ä»£ç ",
                        "åˆ›å»ºæ–°ç›®å½•ç»“æ„",
                        "å®‰è£…æ–°ä¾èµ–"
                    ],
                    "status": "completed"
                },
                {
                    "phase": 2,
                    "name": "æ ¸å¿ƒè¿ç§»",
                    "tasks": [
                        "è¿ç§»Userå®ä½“",
                        "è¿ç§»Orderå®ä½“",
                        "è¿ç§»PaymentæœåŠ¡"
                    ],
                    "status": "pending"
                },
                {
                    "phase": 3,
                    "name": "åŸºç¡€è®¾æ–½",
                    "tasks": [
                        "é…ç½®PostgreSQL",
                        "é…ç½®Redis",
                        "è®¾ç½®ç›‘æ§"
                    ],
                    "status": "pending"
                },
                {
                    "phase": 4,
                    "name": "æµ‹è¯•éªŒè¯",
                    "tasks": [
                        "å•å…ƒæµ‹è¯•",
                        "é›†æˆæµ‹è¯•",
                        "æ€§èƒ½æµ‹è¯•"
                    ],
                    "status": "pending"
                }
            ],
            "modules_to_migrate": {
                "src/premium": "domain/entities/premium + application/commands/premium",
                "src/wallet": "domain/entities/wallet + application/services/wallet",
                "src/energy": "domain/services/energy + infrastructure/external/energy",
                "src/database.py": "infrastructure/database/postgresql",
                "src/bot.py": "presentation/main.py"
            }
        }
        
        plan_file = self.base_path / "migration_plan.json"
        plan_file.write_text(json.dumps(plan, indent=2, ensure_ascii=False))
        print(f"  âœ… ç”Ÿæˆè¿ç§»è®¡åˆ’: {plan_file}")
        
    def generate_requirements(self):
        """ç”Ÿæˆæ–°çš„requirements.txt"""
        print("\nğŸ“¦ æ›´æ–°ä¾èµ–...")
        
        requirements = '''# Core
python-telegram-bot==20.7
python-dotenv==1.0.0

# Database
sqlalchemy==2.0.23
asyncpg==0.29.0
psycopg2-binary==2.9.9
alembic==1.13.0
redis==5.0.1

# Web Framework
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.2
pydantic-settings==2.1.0

# Monitoring
prometheus-client==0.19.0
opentelemetry-api==1.21.0
opentelemetry-sdk==1.21.0
opentelemetry-instrumentation-fastapi==0.42b0

# Utils
httpx==0.25.2
aiofiles==23.2.1
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4

# Development
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
black==23.12.0
flake8==6.1.0
mypy==1.7.1
pre-commit==3.5.0

# Production
gunicorn==21.2.0
supervisor==4.2.5
'''
        (self.base_path / "requirements.prod.txt").write_text(requirements)
        print("  âœ… åˆ›å»º requirements.prod.txt")
        
    def create_makefile(self):
        """åˆ›å»ºMakefile"""
        print("\nğŸ”§ åˆ›å»ºMakefile...")
        
        makefile = '''# Makefile for TG Bot

.PHONY: help install test run docker clean

help:
	@echo "Available commands:"
	@echo "  make install    - Install dependencies"
	@echo "  make test       - Run tests"
	@echo "  make run        - Run bot locally"
	@echo "  make docker     - Build and run with Docker"
	@echo "  make clean      - Clean cache files"

install:
	pip install -r requirements.prod.txt

test:
	pytest tests/ -v --cov=domain --cov=application

run:
	python -m presentation.main

docker:
	docker-compose -f docker-compose.prod.yml up --build

clean:
	find . -type d -name "__pycache__" -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete
	rm -rf .pytest_cache
	rm -rf .coverage
	rm -rf htmlcov

migrate:
	alembic upgrade head

format:
	black .
	isort .

lint:
	flake8 .
	mypy .

security:
	bandit -r domain/ application/ infrastructure/ presentation/
	safety check
'''
        (self.base_path / "Makefile").write_text(makefile)
        print("  âœ… åˆ›å»º Makefile")
        
    def run(self):
        """æ‰§è¡Œè¿ç§»"""
        print("="*60)
        print("ğŸš€ å¼€å§‹æ¶æ„è¿ç§»")
        print("="*60)
        
        # 1. åˆ›å»ºå¤‡ä»½
        self.create_backup()
        
        # 2. åˆ›å»ºDDDç»“æ„
        self.create_ddd_structure()
        
        # 3. åˆ›å»ºåŸºç¡€æ–‡ä»¶
        self.create_base_files()
        
        # 4. åˆ›å»ºDockeræ–‡ä»¶
        self.create_docker_files()
        
        # 5. ç”Ÿæˆè¿ç§»è®¡åˆ’
        self.create_migration_plan()
        
        # 6. æ›´æ–°ä¾èµ–
        self.generate_requirements()
        
        # 7. åˆ›å»ºMakefile
        self.create_makefile()
        
        print("\n"+"="*60)
        print("âœ… æ¶æ„è¿ç§»å‡†å¤‡å®Œæˆï¼")
        print("="*60)
        
        print("\nä¸‹ä¸€æ­¥æ“ä½œï¼š")
        print("1. æŸ¥çœ‹ migration_plan.json äº†è§£è¿ç§»è®¡åˆ’")
        print("2. å¼€å§‹è¿ç§»æ ¸å¿ƒæ¨¡å—åˆ°æ–°æ¶æ„")
        print("3. è¿è¡Œæµ‹è¯•éªŒè¯è¿ç§»ç»“æœ")
        print("4. ä½¿ç”¨ docker-compose.prod.yml éƒ¨ç½²")
        
        print("\nå¿«é€Ÿå‘½ä»¤ï¼š")
        print("  make install  - å®‰è£…ä¾èµ–")
        print("  make test     - è¿è¡Œæµ‹è¯•")
        print("  make docker   - Dockeréƒ¨ç½²")
        

if __name__ == "__main__":
    migration = ArchitectureMigration()
    migration.run()
